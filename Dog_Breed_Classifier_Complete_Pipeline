{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5778981,"sourceType":"datasetVersion","datasetId":3320287}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook solves dog breed classification problem by using EfficientNetV2B2\n\nMax Val_Accuracy : 89.978\nBest Predict on Test : 89.72\n\nAuthor : Devashish Mishra","metadata":{}},{"cell_type":"code","source":"# Cell 1: Kaggle-only config and strategy\nimport os\nfrom pathlib import Path\nimport random\nimport numpy as np\nimport tensorflow as tf\n\n# reproducibility\nSEED = 777\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# ---------- Kaggle dataset detection ----------\nKAGGLE_INPUT_ROOT = \"/kaggle/input\"\nCANDIDATE_DS = [\"120-dog-breed-image-classification\"]\n\ndataset_root = None\nfor d in CANDIDATE_DS:\n    path = os.path.join(KAGGLE_INPUT_ROOT, d)\n    if os.path.exists(path):\n        dataset_root = path\n        break\nif dataset_root is None:\n    entries = sorted(os.listdir(KAGGLE_INPUT_ROOT))\n    if len(entries) == 0:\n        raise FileNotFoundError(\"No datasets under /kaggle/input.\")\n    dataset_root = os.path.join(KAGGLE_INPUT_ROOT, entries[0])\n\n# prefer an 'images' subfolder if present\nif os.path.isdir(os.path.join(dataset_root, \"images\")):\n    SRC_ROOT = os.path.join(dataset_root, \"images\")\nelse:\n    SRC_ROOT = dataset_root\n\n# writable processed output\nPROCESSED_ROOT = \"/kaggle/working/processed_dogs\"\n\n# outputs\nMODEL_DIR = Path(\"/kaggle/working/models\"); MODEL_DIR.mkdir(parents=True, exist_ok=True)\nBEST_PHASEA = MODEL_DIR / \"best_phaseA.keras\"\nBEST_PHASEB = MODEL_DIR / \"best_phaseB.keras\"\nCOMPACT_FINAL = MODEL_DIR / \"final_compact.keras\"\nSAVEDMODEL_DIR = MODEL_DIR / \"savedmodel_backup\"\nTFLITE_OUT = MODEL_DIR / \"final_fp16.tflite\"\n\n# image / training config\nIMG_SIZE = (300, 300)\nALLOWED_EXT = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\nTRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.70, 0.20, 0.10\n\n# single GPU strategy\ngpus = tf.config.list_physical_devices(\"GPU\")\nfor g in gpus:\n    try:\n        tf.config.experimental.set_memory_growth(g, True)\n    except Exception:\n        pass\n\nstrategy = tf.distribute.get_strategy()\n\n# batch size safe for P100\nGLOBAL_BATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\n# two-phase hyperparams\nEPOCHS_HEAD = 10\nLR_HEAD = 1e-5    # lower learning rate for head\nEPOCHS_FINE = 20\nLR_FINE = 1e-6    # safer fine-tuning\nUNFREEZE_TOP_N = 100\n\n\n# print summary\nprint(\"Kaggle dataset root:\", dataset_root)\nprint(\"SRC_ROOT:\", SRC_ROOT)\nprint(\"PROCESSED_ROOT:\", PROCESSED_ROOT)\nprint(\"Strategy:\", type(strategy).__name__)\nprint(\"GLOBAL_BATCH_SIZE:\", GLOBAL_BATCH_SIZE)\nprint(\"IMG_SIZE:\", IMG_SIZE)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:43:07.949131Z","iopub.execute_input":"2025-09-24T14:43:07.949434Z","iopub.status.idle":"2025-09-24T14:43:07.959874Z","shell.execute_reply.started":"2025-09-24T14:43:07.949382Z","shell.execute_reply":"2025-09-24T14:43:07.959093Z"}},"outputs":[{"name":"stdout","text":"Kaggle dataset root: /kaggle/input/120-dog-breed-image-classification\nSRC_ROOT: /kaggle/input/120-dog-breed-image-classification/images\nPROCESSED_ROOT: /kaggle/working/processed_dogs\nStrategy: _DefaultDistributionStrategy\nGLOBAL_BATCH_SIZE: 32\nIMG_SIZE: (300, 300)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Cell 2: Preprocess (resizes + splits per class into train/val/test)\nimport os, shutil, json\nfrom pathlib import Path\nimport random\nimport cv2\nimport pandas as pd\nfrom tqdm import tqdm\n\nrandom.seed(SEED)\n\ndef ensure_dir(p): os.makedirs(p, exist_ok=True)\n\ndef collect_classes(src_root):\n    src = Path(src_root)\n    if not src.exists():\n        raise FileNotFoundError(f\"SRC_ROOT not found: {src_root}\")\n    classes = {}\n    for d in sorted(os.listdir(src_root)):\n        p = src / d\n        if p.is_dir():\n            files = [str(p / f) for f in sorted(os.listdir(p))\n                     if os.path.splitext(f.lower())[1] in ALLOWED_EXT]\n            if files:\n                classes[d] = files\n    return classes\n\ndef resize_image_cv2(path, size):\n    img = cv2.imread(path)\n    if img is None:\n        raise IOError(f\"Failed to read image: {path}\")\n    return cv2.resize(img, (size[0], size[1]), interpolation=cv2.INTER_AREA)\n\ndef save_jpg(img_bgr, out_path, quality=95):\n    ensure_dir(os.path.dirname(out_path))\n    cv2.imwrite(out_path, img_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n\ndef split_per_class(files, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, test_ratio=TEST_RATIO):\n    f = files.copy()\n    random.shuffle(f)\n    n = len(f)\n    if n == 0:\n        return [], [], []\n    train_n = int(round(n * train_ratio))\n    val_n = int(round(n * val_ratio))\n    if train_n == 0 and n >= 1:\n        train_n = 1\n    test_n = n - train_n - val_n\n    if test_n < 0:\n        val_n += test_n\n        test_n = 0\n    if val_n == 0 and n - train_n > 0:\n        val_n = 1\n        test_n = n - train_n - val_n\n    if test_n == 0 and n - train_n - val_n > 0:\n        test_n = n - train_n - val_n\n    if train_n + val_n + test_n != n:\n        remainder = n - (train_n + val_n + test_n)\n        train_n += remainder\n    assert train_n + val_n + test_n == n\n    return f[:train_n], f[train_n:train_n+val_n], f[train_n+val_n:]\n\ndef preprocess_dataset(src_root, out_root, img_size=IMG_SIZE):\n    classes = collect_classes(src_root)\n    class_names = sorted(classes.keys())\n    print(f\"Found {len(class_names)} classes.\")\n    if os.path.exists(out_root):\n        print(\"Removing existing processed folder:\", out_root)\n        shutil.rmtree(out_root)\n    for s in (\"train\",\"val\",\"test\"):\n        ensure_dir(os.path.join(out_root, s))\n\n    class_indices = {i: name for i,name in enumerate(class_names)}\n    ensure_dir(out_root)\n    with open(os.path.join(out_root, \"class_indices.json\"), \"w\") as f:\n        json.dump(class_indices, f, indent=2)\n\n    train_recs, val_recs, test_recs = [], [], []\n    for cls in tqdm(class_names, desc=\"Classes\"):\n        files = classes[cls]\n        tr, va, te = split_per_class(files)\n        def save_list(lst, split_name, recs):\n            out_dir_label = os.path.join(out_root, split_name, cls)\n            ensure_dir(out_dir_label)\n            for src in lst:\n                try:\n                    img = resize_image_cv2(src, img_size)\n                except Exception as e:\n                    print(\"SKIP read error:\", src, e)\n                    continue\n                base = Path(src).stem\n                out_jpg = os.path.join(out_dir_label, base + \".jpg\")\n                save_jpg(img, out_jpg)\n                recs.append({\"orig_path\": src, \"out_jpg\": out_jpg, \"label\": cls})\n        save_list(tr, \"train\", train_recs)\n        save_list(va, \"val\", val_recs)\n        save_list(te, \"test\", test_recs)\n\n    pd.DataFrame(train_recs).to_csv(os.path.join(out_root, \"manifest_train.csv\"), index=False)\n    pd.DataFrame(val_recs).to_csv(os.path.join(out_root, \"manifest_val.csv\"), index=False)\n    pd.DataFrame(test_recs).to_csv(os.path.join(out_root, \"manifest_test.csv\"), index=False)\n\n    # summary counts\n    def counts_from_dir(split_dir):\n        counts = {}\n        for c in class_names:\n            cls_dir = os.path.join(split_dir, c)\n            n = len([f for f in os.listdir(cls_dir) if os.path.splitext(f.lower())[1] in ALLOWED_EXT]) if os.path.isdir(cls_dir) else 0\n            counts[c] = n\n        return counts\n\n    counts = {\"train\": counts_from_dir(os.path.join(out_root,\"train\")),\n              \"val\": counts_from_dir(os.path.join(out_root,\"val\")),\n              \"test\": counts_from_dir(os.path.join(out_root,\"test\"))}\n    totals = {k: sum(v.values()) for k,v in counts.items()}\n    with open(os.path.join(out_root, \"counts_summary.json\"), \"w\") as f:\n        json.dump({\"counts\":counts,\"totals\":totals}, f, indent=2)\n\n    print(\"Done. Totals:\", totals)\n    return out_root\n\n# Run preprocessing if necessary\nif not Path(PROCESSED_ROOT).exists():\n    print(\"Creating processed dataset at:\", PROCESSED_ROOT)\n    preprocess_dataset(SRC_ROOT, PROCESSED_ROOT, img_size=IMG_SIZE)\nelse:\n    print(\"Found existing processed dataset at:\", PROCESSED_ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:32:59.727630Z","iopub.execute_input":"2025-09-24T14:32:59.728136Z","iopub.status.idle":"2025-09-24T14:37:58.944192Z","shell.execute_reply.started":"2025-09-24T14:32:59.728116Z","shell.execute_reply":"2025-09-24T14:37:58.943430Z"}},"outputs":[{"name":"stdout","text":"Creating processed dataset at: /kaggle/working/processed_dogs\nFound 120 classes.\n","output_type":"stream"},{"name":"stderr","text":"Classes: 100%|██████████| 120/120 [04:56<00:00,  2.47s/it]","output_type":"stream"},{"name":"stdout","text":"Done. Totals: {'train': 14397, 'val': 4111, 'test': 2072}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: build tf.data datasets\nimport tensorflow as tf\nfrom pathlib import Path\n\ntrain_dir = str(Path(PROCESSED_ROOT) / \"train\")\nval_dir   = str(Path(PROCESSED_ROOT) / \"val\")\ntest_dir  = str(Path(PROCESSED_ROOT) / \"test\")\n\nprint(\"train_dir:\", train_dir)\nprint(\"val_dir:\", val_dir)\nprint(\"test_dir:\", test_dir)\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    train_dir,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=IMG_SIZE,\n    batch_size=GLOBAL_BATCH_SIZE,\n    shuffle=True,\n    seed=SEED,\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    val_dir,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=IMG_SIZE,\n    batch_size=GLOBAL_BATCH_SIZE,\n    shuffle=False,\n    seed=SEED,\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    test_dir,\n    labels='inferred',\n    label_mode='categorical',\n    image_size=IMG_SIZE,\n    batch_size=GLOBAL_BATCH_SIZE,\n    shuffle=False,\n)\n\nNUM_CLASSES = len(train_ds.class_names)\nprint(\"NUM_CLASSES:\", NUM_CLASSES)\n\n# performance tuning\ntrain_ds = train_ds.prefetch(AUTOTUNE)\nval_ds   = val_ds.prefetch(AUTOTUNE)\ntest_ds  = test_ds.prefetch(AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:37:58.945787Z","iopub.execute_input":"2025-09-24T14:37:58.945977Z","iopub.status.idle":"2025-09-24T14:38:01.571771Z","shell.execute_reply.started":"2025-09-24T14:37:58.945961Z","shell.execute_reply":"2025-09-24T14:38:01.571209Z"}},"outputs":[{"name":"stdout","text":"train_dir: /kaggle/working/processed_dogs/train\nval_dir: /kaggle/working/processed_dogs/val\ntest_dir: /kaggle/working/processed_dogs/test\nFound 14397 files belonging to 120 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1758724679.700229      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Found 4111 files belonging to 120 classes.\nFound 2072 files belonging to 120 classes.\nNUM_CLASSES: 120\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4: build model (EfficientNetV2B2 + stronger head + preprocess_input)\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B2, preprocess_input\n\nwith strategy.scope():\n    data_augmentation = tf.keras.Sequential([\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(0.2),\n        layers.RandomZoom(0.2),\n        layers.RandomContrast(0.1),\n    ], name=\"augmentation\")\n\n    base = EfficientNetV2B2(\n        include_top=False,\n        weights='imagenet',\n        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n    )\n    base.trainable = False\n\n    inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n    x = data_augmentation(inputs)\n    x = preprocess_input(x)         # ✅ official preprocessing\n    x = base(x, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(1024, activation=\"relu\", dtype=\"float32\")(x)\n    x = layers.Dropout(0.5)(x)      # stronger regularization\n    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", dtype=\"float32\")(x)\n\n    model = Model(inputs, outputs)\n\n    model.compile(optimizer=Adam(learning_rate=LR_HEAD),\n                  loss=\"categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:43:40.058947Z","iopub.execute_input":"2025-09-24T14:43:40.059509Z","iopub.status.idle":"2025-09-24T14:43:41.957147Z","shell.execute_reply.started":"2025-09-24T14:43:40.059483Z","shell.execute_reply":"2025-09-24T14:43:41.956439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetv2-b2 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1408\u001b[0m)   │     \u001b[38;5;34m8,769,374\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,442,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │       \u001b[38;5;34m123,000\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetv2-b2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,442,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,000</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,335,190\u001b[0m (39.43 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,335,190</span> (39.43 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,565,816\u001b[0m (5.97 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,565,816</span> (5.97 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,769,374\u001b[0m (33.45 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> (33.45 MB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Cell 5: callbacks\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\ncheckpoint_a = ModelCheckpoint(str(BEST_PHASEA), monitor=\"val_accuracy\", save_best_only=True, verbose=1)\nreducelr_a = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\nearly_a = EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)\n\ncheckpoint_b = ModelCheckpoint(str(BEST_PHASEB), monitor=\"val_accuracy\", save_best_only=True, verbose=1)\nreducelr_b = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\nearly_b = EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:38:06.462622Z","iopub.execute_input":"2025-09-24T14:38:06.462865Z","iopub.status.idle":"2025-09-24T14:38:06.469414Z","shell.execute_reply.started":"2025-09-24T14:38:06.462841Z","shell.execute_reply":"2025-09-24T14:38:06.468957Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Cell 6: train Phase A (head-only)\nprint(\"Phase A: training head only. LR =\", LR_HEAD)\nhistory_a = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS_HEAD,\n    callbacks=[checkpoint_a, reducelr_a, early_a],\n    verbose=1\n)\nprint(\"Phase A done. Best saved to:\", BEST_PHASEA)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:43:51.999269Z","iopub.execute_input":"2025-09-24T14:43:51.999903Z","iopub.status.idle":"2025-09-24T14:52:58.464121Z","shell.execute_reply.started":"2025-09-24T14:43:51.999876Z","shell.execute_reply":"2025-09-24T14:52:58.463433Z"}},"outputs":[{"name":"stdout","text":"Phase A: training head only. LR = 1e-05\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1758725053.582154      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_3_1/efficientnetv2-b2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0204 - loss: 4.7503\nEpoch 1: val_accuracy improved from 0.01168 to 0.28460, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 126ms/step - accuracy: 0.0204 - loss: 4.7501 - val_accuracy: 0.2846 - val_loss: 4.3522 - learning_rate: 1.0000e-05\nEpoch 2/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1420 - loss: 4.3689\nEpoch 2: val_accuracy improved from 0.28460 to 0.64753, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.1421 - loss: 4.3687 - val_accuracy: 0.6475 - val_loss: 3.9079 - learning_rate: 1.0000e-05\nEpoch 3/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3355 - loss: 3.9424\nEpoch 3: val_accuracy improved from 0.64753 to 0.76089, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.3356 - loss: 3.9421 - val_accuracy: 0.7609 - val_loss: 3.4457 - learning_rate: 1.0000e-05\nEpoch 4/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.4603 - loss: 3.5063\nEpoch 4: val_accuracy improved from 0.76089 to 0.80905, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.4604 - loss: 3.5061 - val_accuracy: 0.8090 - val_loss: 2.9789 - learning_rate: 1.0000e-05\nEpoch 5/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5402 - loss: 3.0654\nEpoch 5: val_accuracy improved from 0.80905 to 0.83873, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 116ms/step - accuracy: 0.5402 - loss: 3.0652 - val_accuracy: 0.8387 - val_loss: 2.5319 - learning_rate: 1.0000e-05\nEpoch 6/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5903 - loss: 2.6498\nEpoch 6: val_accuracy improved from 0.83873 to 0.85575, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.5903 - loss: 2.6496 - val_accuracy: 0.8558 - val_loss: 2.1306 - learning_rate: 1.0000e-05\nEpoch 7/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6113 - loss: 2.3179\nEpoch 7: val_accuracy improved from 0.85575 to 0.86646, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 117ms/step - accuracy: 0.6113 - loss: 2.3177 - val_accuracy: 0.8665 - val_loss: 1.7912 - learning_rate: 1.0000e-05\nEpoch 8/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6452 - loss: 2.0208\nEpoch 8: val_accuracy improved from 0.86646 to 0.87375, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6453 - loss: 2.0207 - val_accuracy: 0.8738 - val_loss: 1.5111 - learning_rate: 1.0000e-05\nEpoch 9/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6623 - loss: 1.8074\nEpoch 9: val_accuracy improved from 0.87375 to 0.88202, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6623 - loss: 1.8073 - val_accuracy: 0.8820 - val_loss: 1.2857 - learning_rate: 1.0000e-05\nEpoch 10/10\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6703 - loss: 1.6412\nEpoch 10: val_accuracy improved from 0.88202 to 0.88762, saving model to /kaggle/working/models/best_phaseA.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 115ms/step - accuracy: 0.6703 - loss: 1.6411 - val_accuracy: 0.8876 - val_loss: 1.1074 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 10.\nPhase A done. Best saved to: /kaggle/working/models/best_phaseA.keras\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Cell 7: prepare Phase B (unfreeze top layers)\n# quick hyperparam tweaks for Phase B\nUNFREEZE_TOP_N = 150\nLR_FINE = 1e-5\nEPOCHS_FINE = 30\n\n# load best Phase A\nif Path(BEST_PHASEA).exists():\n    print(\"Loading best Phase A from:\", BEST_PHASEA)\n    model = tf.keras.models.load_model(str(BEST_PHASEA))\nelse:\n    print(\"BEST_PHASEA not found; using current model in memory\")\n\n# unfreeze last UNFREEZE_TOP_N layers\ntotal_layers = len(model.layers)\nstart_unfreeze = max(0, total_layers - UNFREEZE_TOP_N)\nfor i, layer in enumerate(model.layers):\n    layer.trainable = True if i >= start_unfreeze else False\nprint(f\"Unfreezing layers from {start_unfreeze} / {total_layers-1}\")\n\n# recompile with slightly higher LR and label smoothing\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\nwith strategy.scope():\n    opt = Adam(learning_rate=LR_FINE)\n    loss = CategoricalCrossentropy(label_smoothing=0.05)   # stabilizes loss\n    model.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\n\n# callbacks: you can keep the existing ones but increase patience a bit\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\ncheckpoint_b = ModelCheckpoint(str(BEST_PHASEB), monitor=\"val_accuracy\", save_best_only=True, verbose=1)\nreducelr_b = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\nearly_b = EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:06:04.419386Z","iopub.execute_input":"2025-09-24T15:06:04.419996Z","iopub.status.idle":"2025-09-24T15:06:06.262086Z","shell.execute_reply.started":"2025-09-24T15:06:04.419971Z","shell.execute_reply":"2025-09-24T15:06:06.261307Z"}},"outputs":[{"name":"stdout","text":"Loading best Phase A from: /kaggle/working/models/best_phaseA.keras\nUnfreezing layers from 0 / 6\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Cell 8: train Phase B (fine-tune)\n# resume training Phase B\nhistory_b = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS_FINE,\n    callbacks=[checkpoint_b, reducelr_b, early_b],\n    verbose=1\n)\nprint(\"Phase B done. Best saved to:\", BEST_PHASEB)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T15:06:18.003387Z","iopub.execute_input":"2025-09-24T15:06:18.003702Z","iopub.status.idle":"2025-09-24T16:35:46.919010Z","shell.execute_reply.started":"2025-09-24T15:06:18.003683Z","shell.execute_reply":"2025-09-24T16:35:46.918204Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1758726457.085626      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_3_1/efficientnetv2-b2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.4881 - loss: 2.8548\nEpoch 1: val_accuracy improved from -inf to 0.79981, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 404ms/step - accuracy: 0.4882 - loss: 2.8541 - val_accuracy: 0.7998 - val_loss: 1.5889 - learning_rate: 1.0000e-05\nEpoch 2/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.6051 - loss: 1.9554\nEpoch 2: val_accuracy improved from 0.79981 to 0.82754, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 396ms/step - accuracy: 0.6052 - loss: 1.9552 - val_accuracy: 0.8275 - val_loss: 1.2357 - learning_rate: 1.0000e-05\nEpoch 3/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.6514 - loss: 1.6701\nEpoch 3: val_accuracy improved from 0.82754 to 0.84043, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 392ms/step - accuracy: 0.6514 - loss: 1.6700 - val_accuracy: 0.8404 - val_loss: 1.0670 - learning_rate: 1.0000e-05\nEpoch 4/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.6843 - loss: 1.5247\nEpoch 4: val_accuracy improved from 0.84043 to 0.85016, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.6843 - loss: 1.5247 - val_accuracy: 0.8502 - val_loss: 0.9956 - learning_rate: 1.0000e-05\nEpoch 5/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.6967 - loss: 1.4447\nEpoch 5: val_accuracy improved from 0.85016 to 0.85867, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 392ms/step - accuracy: 0.6967 - loss: 1.4446 - val_accuracy: 0.8587 - val_loss: 0.9446 - learning_rate: 1.0000e-05\nEpoch 6/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7229 - loss: 1.3783\nEpoch 6: val_accuracy improved from 0.85867 to 0.86889, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.7229 - loss: 1.3782 - val_accuracy: 0.8689 - val_loss: 0.9019 - learning_rate: 1.0000e-05\nEpoch 7/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7400 - loss: 1.3225\nEpoch 7: val_accuracy improved from 0.86889 to 0.87205, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.7400 - loss: 1.3225 - val_accuracy: 0.8721 - val_loss: 0.8834 - learning_rate: 1.0000e-05\nEpoch 8/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7466 - loss: 1.2828\nEpoch 8: val_accuracy improved from 0.87205 to 0.87424, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 392ms/step - accuracy: 0.7466 - loss: 1.2828 - val_accuracy: 0.8742 - val_loss: 0.8713 - learning_rate: 1.0000e-05\nEpoch 9/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.7590 - loss: 1.2603\nEpoch 9: val_accuracy improved from 0.87424 to 0.87546, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 392ms/step - accuracy: 0.7590 - loss: 1.2602 - val_accuracy: 0.8755 - val_loss: 0.8593 - learning_rate: 1.0000e-05\nEpoch 10/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7699 - loss: 1.2120\nEpoch 10: val_accuracy did not improve from 0.87546\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.7699 - loss: 1.2120 - val_accuracy: 0.8747 - val_loss: 0.8454 - learning_rate: 1.0000e-05\nEpoch 11/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.7763 - loss: 1.1919\nEpoch 11: val_accuracy improved from 0.87546 to 0.88056, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 392ms/step - accuracy: 0.7763 - loss: 1.1919 - val_accuracy: 0.8806 - val_loss: 0.8333 - learning_rate: 1.0000e-05\nEpoch 12/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7805 - loss: 1.1640\nEpoch 12: val_accuracy improved from 0.88056 to 0.88275, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.7805 - loss: 1.1640 - val_accuracy: 0.8828 - val_loss: 0.8208 - learning_rate: 1.0000e-05\nEpoch 13/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7963 - loss: 1.1311\nEpoch 13: val_accuracy improved from 0.88275 to 0.88348, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.7963 - loss: 1.1311 - val_accuracy: 0.8835 - val_loss: 0.8162 - learning_rate: 1.0000e-05\nEpoch 14/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7992 - loss: 1.1205\nEpoch 14: val_accuracy improved from 0.88348 to 0.88397, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.7992 - loss: 1.1205 - val_accuracy: 0.8840 - val_loss: 0.8100 - learning_rate: 1.0000e-05\nEpoch 15/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8071 - loss: 1.1019\nEpoch 15: val_accuracy improved from 0.88397 to 0.88835, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 392ms/step - accuracy: 0.8071 - loss: 1.1019 - val_accuracy: 0.8883 - val_loss: 0.7995 - learning_rate: 1.0000e-05\nEpoch 16/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8119 - loss: 1.0815\nEpoch 16: val_accuracy improved from 0.88835 to 0.89078, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 393ms/step - accuracy: 0.8119 - loss: 1.0815 - val_accuracy: 0.8908 - val_loss: 0.7929 - learning_rate: 1.0000e-05\nEpoch 17/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8202 - loss: 1.0600\nEpoch 17: val_accuracy did not improve from 0.89078\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8202 - loss: 1.0600 - val_accuracy: 0.8886 - val_loss: 0.7910 - learning_rate: 1.0000e-05\nEpoch 18/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8167 - loss: 1.0642\nEpoch 18: val_accuracy improved from 0.89078 to 0.89127, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 392ms/step - accuracy: 0.8167 - loss: 1.0642 - val_accuracy: 0.8913 - val_loss: 0.7911 - learning_rate: 1.0000e-05\nEpoch 19/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8214 - loss: 1.0411\nEpoch 19: val_accuracy did not improve from 0.89127\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8214 - loss: 1.0411 - val_accuracy: 0.8903 - val_loss: 0.7838 - learning_rate: 1.0000e-05\nEpoch 20/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8244 - loss: 1.0282\nEpoch 20: val_accuracy improved from 0.89127 to 0.89224, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 392ms/step - accuracy: 0.8244 - loss: 1.0282 - val_accuracy: 0.8922 - val_loss: 0.7832 - learning_rate: 1.0000e-05\nEpoch 21/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8364 - loss: 0.9984\nEpoch 21: val_accuracy did not improve from 0.89224\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8364 - loss: 0.9985 - val_accuracy: 0.8922 - val_loss: 0.7809 - learning_rate: 1.0000e-05\nEpoch 22/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8342 - loss: 1.0035\nEpoch 22: val_accuracy did not improve from 0.89224\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8342 - loss: 1.0035 - val_accuracy: 0.8910 - val_loss: 0.7806 - learning_rate: 1.0000e-05\nEpoch 23/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8392 - loss: 0.9885\nEpoch 23: val_accuracy improved from 0.89224 to 0.89419, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 392ms/step - accuracy: 0.8392 - loss: 0.9884 - val_accuracy: 0.8942 - val_loss: 0.7774 - learning_rate: 1.0000e-05\nEpoch 24/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8411 - loss: 0.9791\nEpoch 24: val_accuracy improved from 0.89419 to 0.89613, saving model to /kaggle/working/models/best_phaseB.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 392ms/step - accuracy: 0.8411 - loss: 0.9791 - val_accuracy: 0.8961 - val_loss: 0.7712 - learning_rate: 1.0000e-05\nEpoch 25/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8490 - loss: 0.9584\nEpoch 25: val_accuracy did not improve from 0.89613\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8490 - loss: 0.9584 - val_accuracy: 0.8949 - val_loss: 0.7684 - learning_rate: 1.0000e-05\nEpoch 26/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.8498 - loss: 0.9553\nEpoch 26: val_accuracy did not improve from 0.89613\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 387ms/step - accuracy: 0.8499 - loss: 0.9552 - val_accuracy: 0.8939 - val_loss: 0.7697 - learning_rate: 1.0000e-05\nEpoch 27/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8586 - loss: 0.9391\nEpoch 27: val_accuracy did not improve from 0.89613\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.8586 - loss: 0.9391 - val_accuracy: 0.8944 - val_loss: 0.7645 - learning_rate: 1.0000e-05\nEpoch 28/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.8577 - loss: 0.9324\nEpoch 28: val_accuracy did not improve from 0.89613\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 387ms/step - accuracy: 0.8577 - loss: 0.9324 - val_accuracy: 0.8956 - val_loss: 0.7610 - learning_rate: 1.0000e-05\nEpoch 29/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8602 - loss: 0.9195\nEpoch 29: val_accuracy did not improve from 0.89613\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 387ms/step - accuracy: 0.8602 - loss: 0.9195 - val_accuracy: 0.8944 - val_loss: 0.7642 - learning_rate: 1.0000e-05\nEpoch 30/30\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8638 - loss: 0.9135\nEpoch 30: val_accuracy did not improve from 0.89613\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 387ms/step - accuracy: 0.8638 - loss: 0.9135 - val_accuracy: 0.8944 - val_loss: 0.7644 - learning_rate: 1.0000e-05\nRestoring model weights from the end of the best epoch: 28.\nPhase B done. Best saved to: /kaggle/working/models/best_phaseB.keras\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Option A: Continue fine-tuning, save final_model.keras, evaluate on test_ds\nfrom pathlib import Path\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\n# --- hyperparams (tweakable) ---\nUNFREEZE_TOP_N = 250        # last N layers to unfreeze\nLR_CONT = 3e-5              # small LR for continued fine-tuning\nEPOCHS_CONT = 20            # run a few to many epochs\nPATIENCE = 6                # early stopping patience\nFINAL_OUT = MODEL_DIR / \"final_model.keras\"   # where final model will be saved\n\n# --- load best Phase B checkpoint ---\nif not Path(BEST_PHASEB).exists():\n    raise FileNotFoundError(f\"BEST_PHASEB not found at {BEST_PHASEB}\")\nmodel = tf.keras.models.load_model(str(BEST_PHASEB))\nprint(\"Loaded BEST_PHASEB:\", BEST_PHASEB)\n\n# --- unfreeze last UNFREEZE_TOP_N layers ---\ntotal_layers = len(model.layers)\nstart_unfreeze = max(0, total_layers - UNFREEZE_TOP_N)\nfor i, layer in enumerate(model.layers):\n    layer.trainable = True if i >= start_unfreeze else False\nprint(f\"Unfrozen layers from index {start_unfreeze} / {total_layers-1}\")\n\n# --- recompile with small LR and label smoothing ---\nopt = Adam(learning_rate=LR_CONT)\nloss = CategoricalCrossentropy(label_smoothing=0.05)\nmodel.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\nmodel.summary()\n\n# --- callbacks (save best during this continuation) ---\nckpt = ModelCheckpoint(str(MODEL_DIR / \"cont_finetune_best.keras\"),\n                       monitor=\"val_accuracy\", save_best_only=True, verbose=1)\nreducelr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\nearly = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=1)\n\n# --- train ---\nhistory_cont = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS_CONT,\n    callbacks=[ckpt, reducelr, early],\n    verbose=1\n)\n\n# --- after training: pick the best checkpoint (if exists) and save as final_model.keras ---\nbest_cont_path = MODEL_DIR / \"cont_finetune_best.keras\"\nif best_cont_path.exists():\n    final = tf.keras.models.load_model(str(best_cont_path))\n    print(\"Loaded continuation best from:\", best_cont_path)\nelse:\n    final = model\n    print(\"Using last-in-memory model as final.\")\n\n# save final model in native Keras format\nfinal.save(str(FINAL_OUT), include_optimizer=False)\nprint(\"Saved final model ->\", FINAL_OUT)\n\n# --- evaluation on test_ds ---\ny_true, y_pred = [], []\nfor imgs, labs in test_ds:\n    probs = final.predict(imgs, verbose=0)\n    y_true.extend(np.argmax(labs.numpy(), axis=1).tolist())\n    y_pred.extend(np.argmax(probs, axis=1).tolist())\n\nacc = accuracy_score(y_true, y_pred)\nprint(f\"\\nFinal test accuracy: {acc:.4f}\")\nprint(\"\\nClassification report:\")\nprint(classification_report(y_true, y_pred, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T16:56:20.489749Z","iopub.execute_input":"2025-09-24T16:56:20.490302Z","iopub.status.idle":"2025-09-24T17:44:56.955447Z","shell.execute_reply.started":"2025-09-24T16:56:20.490280Z","shell.execute_reply":"2025-09-24T17:44:56.954776Z"}},"outputs":[{"name":"stdout","text":"Loaded BEST_PHASEB: /kaggle/working/models/best_phaseB.keras\nUnfrozen layers from index 0 / 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetv2-b2 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1408\u001b[0m)   │     \u001b[38;5;34m8,769,374\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,442,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │       \u001b[38;5;34m123,000\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetv2-b2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,442,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,000</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,335,190\u001b[0m (39.43 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,335,190</span> (39.43 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,252,902\u001b[0m (39.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,252,902</span> (39.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m82,288\u001b[0m (321.44 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,288</span> (321.44 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1758733062.944949      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_3_1/efficientnetv2-b2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8456 - loss: 0.9693\nEpoch 1: val_accuracy improved from -inf to 0.89467, saving model to /kaggle/working/models/cont_finetune_best.keras\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 403ms/step - accuracy: 0.8456 - loss: 0.9693 - val_accuracy: 0.8947 - val_loss: 0.7695 - learning_rate: 3.0000e-05\nEpoch 2/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8535 - loss: 0.9544\nEpoch 2: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.8535 - loss: 0.9544 - val_accuracy: 0.8927 - val_loss: 0.7745 - learning_rate: 3.0000e-05\nEpoch 3/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8577 - loss: 0.9303\nEpoch 3: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.8577 - loss: 0.9303 - val_accuracy: 0.8908 - val_loss: 0.7774 - learning_rate: 3.0000e-05\nEpoch 4/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8724 - loss: 0.8945\nEpoch 4: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8724 - loss: 0.8945 - val_accuracy: 0.8927 - val_loss: 0.7685 - learning_rate: 3.0000e-05\nEpoch 5/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8748 - loss: 0.8844\nEpoch 5: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8748 - loss: 0.8844 - val_accuracy: 0.8944 - val_loss: 0.7663 - learning_rate: 3.0000e-05\nEpoch 6/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8785 - loss: 0.8707\nEpoch 6: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.8785 - loss: 0.8707 - val_accuracy: 0.8920 - val_loss: 0.7681 - learning_rate: 3.0000e-05\nEpoch 7/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8836 - loss: 0.8547\nEpoch 7: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.8836 - loss: 0.8547 - val_accuracy: 0.8908 - val_loss: 0.7677 - learning_rate: 3.0000e-05\nEpoch 8/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8880 - loss: 0.8347\nEpoch 8: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8880 - loss: 0.8347 - val_accuracy: 0.8932 - val_loss: 0.7659 - learning_rate: 3.0000e-05\nEpoch 9/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8921 - loss: 0.8183\nEpoch 9: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.8921 - loss: 0.8183 - val_accuracy: 0.8932 - val_loss: 0.7713 - learning_rate: 3.0000e-05\nEpoch 10/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8955 - loss: 0.8073\nEpoch 10: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.8955 - loss: 0.8073 - val_accuracy: 0.8918 - val_loss: 0.7597 - learning_rate: 3.0000e-05\nEpoch 11/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9048 - loss: 0.7925\nEpoch 11: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 389ms/step - accuracy: 0.9048 - loss: 0.7925 - val_accuracy: 0.8879 - val_loss: 0.7779 - learning_rate: 3.0000e-05\nEpoch 12/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9048 - loss: 0.7832\nEpoch 12: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.9048 - loss: 0.7832 - val_accuracy: 0.8881 - val_loss: 0.7748 - learning_rate: 3.0000e-05\nEpoch 13/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9134 - loss: 0.7657\nEpoch 13: val_accuracy did not improve from 0.89467\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.9134 - loss: 0.7657 - val_accuracy: 0.8935 - val_loss: 0.7759 - learning_rate: 3.0000e-05\nEpoch 14/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9174 - loss: 0.7604\nEpoch 14: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.9174 - loss: 0.7603 - val_accuracy: 0.8888 - val_loss: 0.7772 - learning_rate: 1.5000e-05\nEpoch 15/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9225 - loss: 0.7441\nEpoch 15: val_accuracy did not improve from 0.89467\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.9225 - loss: 0.7440 - val_accuracy: 0.8896 - val_loss: 0.7761 - learning_rate: 1.5000e-05\nEpoch 16/20\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9295 - loss: 0.7244\nEpoch 16: val_accuracy did not improve from 0.89467\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-06.\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 388ms/step - accuracy: 0.9294 - loss: 0.7244 - val_accuracy: 0.8866 - val_loss: 0.7804 - learning_rate: 1.5000e-05\nEpoch 16: early stopping\nRestoring model weights from the end of the best epoch: 10.\nLoaded continuation best from: /kaggle/working/models/cont_finetune_best.keras\nSaved final model -> /kaggle/working/models/final_model.keras\n\nFinal test accuracy: 0.8856\n\nClassification report:\n              precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000        24\n           1     0.9444    1.0000    0.9714        17\n           2     0.8750    1.0000    0.9333        21\n           3     0.6667    0.7500    0.7059        16\n           4     0.6667    0.9333    0.7778        15\n           5     0.7059    0.6000    0.6486        20\n           6     1.0000    1.0000    1.0000        19\n           7     0.9500    0.9048    0.9268        21\n           8     0.8500    0.9444    0.8947        18\n           9     0.7778    0.9333    0.8485        15\n          10     1.0000    1.0000    1.0000        18\n          11     0.8182    0.9474    0.8780        19\n          12     0.9333    0.9333    0.9333        15\n          13     1.0000    0.9333    0.9655        15\n          14     1.0000    0.9375    0.9677        16\n          15     0.9286    0.8125    0.8667        16\n          16     0.8889    0.9412    0.9143        17\n          17     0.8333    0.6250    0.7143        16\n          18     1.0000    0.8889    0.9412        18\n          19     0.9333    0.9333    0.9333        15\n          20     0.8333    0.6250    0.7143        16\n          21     0.8889    1.0000    0.9412        16\n          22     1.0000    1.0000    1.0000        16\n          23     0.7391    0.8095    0.7727        21\n          24     0.4286    0.2000    0.2727        15\n          25     0.9333    0.8750    0.9032        16\n          26     1.0000    0.9375    0.9677        16\n          27     1.0000    1.0000    1.0000        16\n          28     1.0000    1.0000    1.0000        15\n          29     1.0000    1.0000    1.0000        16\n          30     0.9091    0.9524    0.9302        21\n          31     0.9000    0.5625    0.6923        16\n          32     1.0000    1.0000    1.0000        18\n          33     1.0000    0.9375    0.9677        16\n          34     0.9333    0.8235    0.8750        17\n          35     0.9333    0.9333    0.9333        15\n          36     0.8182    0.8571    0.8372        21\n          37     0.8947    0.8947    0.8947        19\n          38     0.9375    0.8333    0.8824        18\n          39     1.0000    0.9444    0.9714        18\n          40     0.8421    0.9412    0.8889        17\n          41     0.9375    0.7500    0.8333        20\n          42     1.0000    0.9524    0.9756        21\n          43     0.8667    0.6842    0.7647        19\n          44     0.8065    0.9615    0.8772        26\n          45     1.0000    1.0000    1.0000        16\n          46     0.8333    1.0000    0.9091        20\n          47     0.8824    0.8333    0.8571        18\n          48     0.9524    1.0000    0.9756        20\n          49     0.7895    0.8333    0.8108        18\n          50     0.9444    1.0000    0.9714        17\n          51     0.9333    0.9333    0.9333        15\n          52     0.7500    1.0000    0.8571        18\n          53     0.8800    1.0000    0.9362        22\n          54     0.8889    0.8889    0.8889        18\n          55     0.9375    0.9375    0.9375        16\n          56     0.9444    1.0000    0.9714        17\n          57     0.9524    1.0000    0.9756        20\n          58     0.9545    1.0000    0.9767        21\n          59     0.8750    0.9333    0.9032        15\n          60     0.9167    0.9167    0.9167        24\n          61     1.0000    1.0000    1.0000        21\n          62     0.8824    0.9375    0.9091        16\n          63     0.7391    0.8095    0.7727        21\n          64     0.5185    0.7000    0.5957        20\n          65     0.7500    0.7500    0.7500        16\n          66     0.8750    0.9333    0.9032        15\n          67     0.9231    0.7500    0.8276        16\n          68     0.9048    0.9048    0.9048        21\n          69     0.6000    0.8000    0.6857        15\n          70     0.9412    1.0000    0.9697        16\n          71     0.9286    0.8667    0.8966        15\n          72     0.8421    0.9412    0.8889        17\n          73     0.5789    0.6875    0.6286        16\n          74     0.8824    1.0000    0.9375        15\n          75     0.9091    0.9524    0.9302        21\n          76     0.9412    0.8889    0.9143        18\n          77     0.8182    0.9000    0.8571        20\n          78     0.8824    0.9375    0.9091        16\n          79     0.8947    0.8947    0.8947        19\n          80     1.0000    0.8824    0.9375        17\n          81     0.9375    1.0000    0.9677        15\n          82     0.9231    0.8000    0.8571        15\n          83     0.9412    1.0000    0.9697        16\n          84     0.9333    0.8750    0.9032        16\n          85     0.8261    0.9500    0.8837        20\n          86     1.0000    0.8500    0.9189        20\n          87     1.0000    1.0000    1.0000        15\n          88     1.0000    0.8125    0.8966        16\n          89     0.8333    0.6667    0.7407        15\n          90     0.8750    0.9333    0.9032        15\n          91     1.0000    0.9333    0.9655        15\n          92     0.8750    0.8750    0.8750        16\n          93     0.8824    0.9375    0.9091        16\n          94     0.8125    0.8125    0.8125        16\n          95     0.9286    0.8667    0.8966        15\n          96     1.0000    1.0000    1.0000        15\n          97     1.0000    1.0000    1.0000        15\n          98     0.9286    0.8667    0.8966        15\n          99     0.8824    1.0000    0.9375        15\n         100     0.8750    0.9333    0.9032        15\n         101     0.9333    0.8235    0.8750        17\n         102     0.9333    0.9333    0.9333        15\n         103     0.8947    0.9444    0.9189        18\n         104     0.7692    0.6250    0.6897        16\n         105     0.8750    0.9333    0.9032        15\n         106     0.8333    0.6667    0.7407        15\n         107     0.9524    1.0000    0.9756        20\n         108     0.8636    0.9500    0.9048        20\n         109     0.7692    0.7143    0.7407        14\n         110     0.9333    0.9333    0.9333        15\n         111     0.7500    0.6667    0.7059        18\n         112     0.8750    0.8750    0.8750        16\n         113     0.9286    0.8125    0.8667        16\n         114     0.9231    0.7500    0.8276        16\n         115     0.6667    0.6667    0.6667        15\n         116     1.0000    0.8333    0.9091        18\n         117     1.0000    0.9333    0.9655        15\n         118     0.9286    0.6842    0.7879        19\n         119     0.8125    0.8125    0.8125        16\n\n    accuracy                         0.8856      2072\n   macro avg     0.8893    0.8831    0.8827      2072\nweighted avg     0.8893    0.8856    0.8840      2072\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Cell 9: evaluation\nimport numpy as np\nfrom sklearn.metrics import classification_report, accuracy_score\n\nif Path(BEST_PHASEB).exists():\n    final_model = tf.keras.models.load_model(str(BEST_PHASEB))\n    print(\"Loaded BEST_PHASEB for evaluation\")\nelse:\n    final_model = model\n    print(\"Evaluating current model in memory\")\n\ny_true, y_pred = [], []\nfor imgs, labs in test_ds:\n    probs = final_model.predict(imgs, verbose=0)\n    y_true.extend(np.argmax(labs.numpy(), axis=1).tolist())\n    y_pred.extend(np.argmax(probs, axis=1).tolist())\n\nacc = accuracy_score(y_true, y_pred)\nprint(f\"Test accuracy: {acc:.4f}\")\nprint(\"Classification report:\")\nprint(classification_report(y_true, y_pred, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T17:45:32.963883Z","iopub.execute_input":"2025-09-24T17:45:32.964157Z","iopub.status.idle":"2025-09-24T17:45:58.903906Z","shell.execute_reply.started":"2025-09-24T17:45:32.964135Z","shell.execute_reply":"2025-09-24T17:45:58.903146Z"}},"outputs":[{"name":"stdout","text":"Loaded BEST_PHASEB for evaluation\nTest accuracy: 0.8900\nClassification report:\n              precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000        24\n           1     0.9444    1.0000    0.9714        17\n           2     0.9091    0.9524    0.9302        21\n           3     0.6316    0.7500    0.6857        16\n           4     0.8125    0.8667    0.8387        15\n           5     0.7222    0.6500    0.6842        20\n           6     1.0000    1.0000    1.0000        19\n           7     0.9500    0.9048    0.9268        21\n           8     0.8571    1.0000    0.9231        18\n           9     0.7778    0.9333    0.8485        15\n          10     1.0000    0.9444    0.9714        18\n          11     0.8636    1.0000    0.9268        19\n          12     1.0000    0.8667    0.9286        15\n          13     1.0000    0.9333    0.9655        15\n          14     0.9333    0.8750    0.9032        16\n          15     0.9333    0.8750    0.9032        16\n          16     0.8947    1.0000    0.9444        17\n          17     0.8333    0.6250    0.7143        16\n          18     1.0000    0.8889    0.9412        18\n          19     1.0000    0.8667    0.9286        15\n          20     0.8333    0.6250    0.7143        16\n          21     0.9333    0.8750    0.9032        16\n          22     1.0000    1.0000    1.0000        16\n          23     0.7917    0.9048    0.8444        21\n          24     0.2857    0.1333    0.1818        15\n          25     0.9375    0.9375    0.9375        16\n          26     1.0000    0.9375    0.9677        16\n          27     1.0000    0.8750    0.9333        16\n          28     0.9375    1.0000    0.9677        15\n          29     1.0000    1.0000    1.0000        16\n          30     0.9091    0.9524    0.9302        21\n          31     0.8571    0.7500    0.8000        16\n          32     1.0000    1.0000    1.0000        18\n          33     1.0000    0.9375    0.9677        16\n          34     0.9375    0.8824    0.9091        17\n          35     0.9375    1.0000    0.9677        15\n          36     0.8261    0.9048    0.8636        21\n          37     0.8500    0.8947    0.8718        19\n          38     1.0000    0.8333    0.9091        18\n          39     1.0000    0.9444    0.9714        18\n          40     0.8889    0.9412    0.9143        17\n          41     0.8333    0.7500    0.7895        20\n          42     1.0000    0.9524    0.9756        21\n          43     0.8667    0.6842    0.7647        19\n          44     0.8387    1.0000    0.9123        26\n          45     1.0000    1.0000    1.0000        16\n          46     0.8000    1.0000    0.8889        20\n          47     0.8333    0.8333    0.8333        18\n          48     0.9524    1.0000    0.9756        20\n          49     0.8000    0.8889    0.8421        18\n          50     0.9444    1.0000    0.9714        17\n          51     0.9333    0.9333    0.9333        15\n          52     0.8182    1.0000    0.9000        18\n          53     0.9167    1.0000    0.9565        22\n          54     0.8824    0.8333    0.8571        18\n          55     0.9412    1.0000    0.9697        16\n          56     0.9444    1.0000    0.9714        17\n          57     0.9524    1.0000    0.9756        20\n          58     0.9524    0.9524    0.9524        21\n          59     0.9286    0.8667    0.8966        15\n          60     0.9545    0.8750    0.9130        24\n          61     1.0000    1.0000    1.0000        21\n          62     0.8824    0.9375    0.9091        16\n          63     0.7600    0.9048    0.8261        21\n          64     0.5217    0.6000    0.5581        20\n          65     0.7500    0.7500    0.7500        16\n          66     0.8750    0.9333    0.9032        15\n          67     1.0000    0.6875    0.8148        16\n          68     0.9048    0.9048    0.9048        21\n          69     0.6111    0.7333    0.6667        15\n          70     0.8889    1.0000    0.9412        16\n          71     0.9286    0.8667    0.8966        15\n          72     0.8889    0.9412    0.9143        17\n          73     0.6667    0.7500    0.7059        16\n          74     0.8824    1.0000    0.9375        15\n          75     0.9091    0.9524    0.9302        21\n          76     0.9444    0.9444    0.9444        18\n          77     0.7917    0.9500    0.8636        20\n          78     0.9375    0.9375    0.9375        16\n          79     0.9444    0.8947    0.9189        19\n          80     0.9375    0.8824    0.9091        17\n          81     0.9375    1.0000    0.9677        15\n          82     0.9231    0.8000    0.8571        15\n          83     1.0000    1.0000    1.0000        16\n          84     0.9375    0.9375    0.9375        16\n          85     0.8261    0.9500    0.8837        20\n          86     0.9474    0.9000    0.9231        20\n          87     0.9375    1.0000    0.9677        15\n          88     1.0000    0.8125    0.8966        16\n          89     0.8333    0.6667    0.7407        15\n          90     0.9333    0.9333    0.9333        15\n          91     1.0000    0.9333    0.9655        15\n          92     0.8750    0.8750    0.8750        16\n          93     0.8824    0.9375    0.9091        16\n          94     0.7895    0.9375    0.8571        16\n          95     0.8750    0.9333    0.9032        15\n          96     1.0000    1.0000    1.0000        15\n          97     1.0000    1.0000    1.0000        15\n          98     0.8667    0.8667    0.8667        15\n          99     0.8824    1.0000    0.9375        15\n         100     0.9333    0.9333    0.9333        15\n         101     0.7500    0.8824    0.8108        17\n         102     0.9333    0.9333    0.9333        15\n         103     0.8500    0.9444    0.8947        18\n         104     0.7500    0.5625    0.6429        16\n         105     0.8750    0.9333    0.9032        15\n         106     0.9091    0.6667    0.7692        15\n         107     0.9524    1.0000    0.9756        20\n         108     0.9524    1.0000    0.9756        20\n         109     0.7692    0.7143    0.7407        14\n         110     1.0000    0.9333    0.9655        15\n         111     0.7333    0.6111    0.6667        18\n         112     0.8750    0.8750    0.8750        16\n         113     0.9286    0.8125    0.8667        16\n         114     0.9231    0.7500    0.8276        16\n         115     0.6250    0.6667    0.6452        15\n         116     1.0000    0.8333    0.9091        18\n         117     0.9375    1.0000    0.9677        15\n         118     0.9231    0.6316    0.7500        19\n         119     0.8235    0.8750    0.8485        16\n\n    accuracy                         0.8900      2072\n   macro avg     0.8916    0.8870    0.8860      2072\nweighted avg     0.8919    0.8900    0.8877      2072\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Progressive-resize (320x320) starting from best_phaseB.keras\n# Run this cell to fine-tune at 320x320 using BEST Phase B weights as the source.\n\n# Progressive-resize (320x320) starting from best_phaseB.keras\n# Corrected: keep raw datasets to read class_names before prefetch.\nfrom pathlib import Path\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B2, preprocess_input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# ---------- params ----------\nNEW_IMG_SIZE = (320, 320)\nBATCH_SIZE_320 = 24           # try 24 on P100; reduce to 16 if OOM\nUNFREEZE_TOP_N = 250\nLR_RESIZE = 3e-6\nEPOCHS_RESIZE = 18\nPATIENCE = 5\nFINAL_RESIZED = MODEL_DIR / \"best_phaseB.keras\"\n\nSRC_TRAIN = str(Path(PROCESSED_ROOT) / \"train\")\nSRC_VAL   = str(Path(PROCESSED_ROOT) / \"val\")\nSRC_TEST  = str(Path(PROCESSED_ROOT) / \"test\")\n\n# ---------- sanity checks ----------\nassert Path(SRC_TRAIN).exists(), f\"Train folder not found: {SRC_TRAIN}\"\nassert Path(SRC_VAL).exists(), f\"Val folder not found: {SRC_VAL}\"\nassert Path(SRC_TEST).exists(), f\"Test folder not found: {SRC_TEST}\"\nbest_phaseb_path = MODEL_DIR / \"best_phaseB.keras\"\nassert best_phaseb_path.exists(), f\"best_phaseB.keras not found at {best_phaseb_path}\"\n\n# ---------- datasets at 320 (keep raw dataset to access class_names/cardinality) ----------\ntrain_ds_320_raw = tf.keras.utils.image_dataset_from_directory(\n    SRC_TRAIN, labels='inferred', label_mode='categorical',\n    image_size=NEW_IMG_SIZE, batch_size=BATCH_SIZE_320, shuffle=True, seed=SEED\n)\nval_ds_320_raw = tf.keras.utils.image_dataset_from_directory(\n    SRC_VAL, labels='inferred', label_mode='categorical',\n    image_size=NEW_IMG_SIZE, batch_size=BATCH_SIZE_320, shuffle=False, seed=SEED\n)\ntest_ds_320_raw = tf.keras.utils.image_dataset_from_directory(\n    SRC_TEST, labels='inferred', label_mode='categorical',\n    image_size=NEW_IMG_SIZE, batch_size=BATCH_SIZE_320, shuffle=False, seed=SEED\n)\n\n# read class names and batch counts from the raw datasets\nNUM_CLASSES = len(train_ds_320_raw.class_names)\ntrain_batches = tf.data.experimental.cardinality(train_ds_320_raw).numpy()\nprint(\"NUM_CLASSES:\", NUM_CLASSES, \"Train batches:\", train_batches)\n\n# now safely add performance transforms\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds_320 = train_ds_320_raw.prefetch(AUTOTUNE)\nval_ds_320   = val_ds_320_raw.prefetch(AUTOTUNE)\ntest_ds_320  = test_ds_320_raw.prefetch(AUTOTUNE)\n\n# ---------- build model (320) ----------\ninputs = layers.Input(shape=(NEW_IMG_SIZE[0], NEW_IMG_SIZE[1], 3))\n# mild augmentation\nx = layers.RandomFlip(\"horizontal\")(inputs)\nx = layers.RandomRotation(0.15)(x)\nx = layers.RandomZoom(0.12)(x)\nx = layers.RandomContrast(0.08)(x)\nx = preprocess_input(x)\n\nbase = EfficientNetV2B2(include_top=False, weights=None, input_shape=(NEW_IMG_SIZE[0], NEW_IMG_SIZE[1], 3))\nx = base(x, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(1024, activation=\"relu\", dtype=\"float32\")(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", dtype=\"float32\")(x)\nmodel_320 = Model(inputs, outputs)\n\n# ---------- load weights from best_phaseB.keras ----------\nsrc_path = best_phaseb_path\nprint(\"Loading weights from:\", src_path)\nsrc_model = tf.keras.models.load_model(str(src_path))\n\n# Try direct set_weights; fall back to per-layer matching if shapes differ\ntry:\n    model_320.set_weights(src_model.get_weights())\n    print(\"Directly loaded weights from best_phaseB.keras\")\nexcept Exception as e:\n    print(\"Direct load failed (likely shape mismatch). Attempting best-effort layer-wise copy. Error:\", e)\n    copied = 0\n    src_by_name = {l.name: l for l in src_model.layers}\n    for tgt in model_320.layers:\n        if tgt.name in src_by_name:\n            src_w = src_by_name[tgt.name].get_weights()\n            if not src_w:\n                continue\n            try:\n                tgt.set_weights(src_w)\n                copied += 1\n            except Exception:\n                # shape mismatch for this layer — skip\n                continue\n    print(f\"Copied weights for {copied} layers (best-effort).\")\n\n# ---------- unfreeze top N ----------\ntotal_layers = len(model_320.layers)\nstart_unfreeze = max(0, total_layers - UNFREEZE_TOP_N)\nfor i, layer in enumerate(model_320.layers):\n    layer.trainable = True if i >= start_unfreeze else False\nprint(f\"Unfrozen layers from {start_unfreeze}/{total_layers-1} (total layers: {total_layers})\")\n\n# ---------- compile ----------\nopt = Adam(learning_rate=LR_RESIZE)\nloss = CategoricalCrossentropy(label_smoothing=0.05)\nmodel_320.compile(optimizer=opt, loss=loss, metrics=[\"accuracy\"])\nmodel_320.summary()\n\n# ---------- callbacks ----------\nckpt = ModelCheckpoint(str(MODEL_DIR / \"best_resize.keras\"), monitor=\"val_accuracy\", save_best_only=True, verbose=1)\nreducelr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\nearly = EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, restore_best_weights=True, verbose=1)\n\n# ---------- train ----------\nhistory_resize = model_320.fit(\n    train_ds_320,\n    validation_data=val_ds_320,\n    epochs=EPOCHS_RESIZE,\n    callbacks=[ckpt, reducelr, early],\n    verbose=1\n)\n\n# ---------- save best & evaluate ----------\nbest_resize = MODEL_DIR / \"best_resize.keras\"\nif best_resize.exists():\n    final_model = tf.keras.models.load_model(str(best_resize))\n    print(\"Loaded best resize model:\", best_resize)\nelse:\n    final_model = model_320\n\nfinal_model.save(str(FINAL_RESIZED), include_optimizer=False)\nprint(\"Saved final resized model ->\", FINAL_RESIZED)\n\n# evaluate on test set\ny_true, y_pred = [], []\nfor imgs, labs in test_ds_320:\n    probs = final_model.predict(imgs, verbose=0)\n    y_true.extend(np.argmax(labs.numpy(), axis=1).tolist())\n    y_pred.extend(np.argmax(probs, axis=1).tolist())\n\nacc = accuracy_score(y_true, y_pred)\nprint(f\"\\nFinal test accuracy (320×320): {acc:.4f}\")\nprint(classification_report(y_true, y_pred, digits=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T18:19:20.372888Z","iopub.execute_input":"2025-09-24T18:19:20.373160Z","iopub.status.idle":"2025-09-24T19:04:47.741951Z","shell.execute_reply.started":"2025-09-24T18:19:20.373141Z","shell.execute_reply":"2025-09-24T19:04:47.741184Z"}},"outputs":[{"name":"stdout","text":"Found 14397 files belonging to 120 classes.\nFound 4111 files belonging to 120 classes.\nFound 2072 files belonging to 120 classes.\nNUM_CLASSES: 120 Train batches: 600\nLoading weights from: /kaggle/working/models/best_phaseB.keras\nDirectly loaded weights from best_phaseB.keras\nUnfrozen layers from 0/9 (total layers: 10)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_32\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_32\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_flip_2 (\u001b[38;5;33mRandomFlip\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_rotation_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mRandomRotation\u001b[0m)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_zoom_2 (\u001b[38;5;33mRandomZoom\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_contrast_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mRandomContrast\u001b[0m)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetv2-b2 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1408\u001b[0m)   │     \u001b[38;5;34m8,769,374\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,442,816\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │       \u001b[38;5;34m123,000\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_flip_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_rotation_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_zoom_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomZoom</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ random_contrast_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomContrast</span>)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ efficientnetv2-b2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,442,816</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,000</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,335,190\u001b[0m (39.43 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,335,190</span> (39.43 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,252,902\u001b[0m (39.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,252,902</span> (39.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m82,288\u001b[0m (321.44 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,288</span> (321.44 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/18\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1758738046.169510      36 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_32_1/efficientnetv2-b2_1/block1b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.8560 - loss: 0.9486\nEpoch 1: val_accuracy improved from -inf to 0.89540, saving model to /kaggle/working/models/best_resize.keras\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 346ms/step - accuracy: 0.8560 - loss: 0.9486 - val_accuracy: 0.8954 - val_loss: 0.7697 - learning_rate: 3.0000e-06\nEpoch 2/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8507 - loss: 0.9565\nEpoch 2: val_accuracy improved from 0.89540 to 0.89613, saving model to /kaggle/working/models/best_resize.keras\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 334ms/step - accuracy: 0.8507 - loss: 0.9565 - val_accuracy: 0.8961 - val_loss: 0.7623 - learning_rate: 3.0000e-06\nEpoch 3/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8572 - loss: 0.9439\nEpoch 3: val_accuracy improved from 0.89613 to 0.89832, saving model to /kaggle/working/models/best_resize.keras\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 334ms/step - accuracy: 0.8572 - loss: 0.9439 - val_accuracy: 0.8983 - val_loss: 0.7565 - learning_rate: 3.0000e-06\nEpoch 4/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8582 - loss: 0.9466\nEpoch 4: val_accuracy improved from 0.89832 to 0.89929, saving model to /kaggle/working/models/best_resize.keras\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 334ms/step - accuracy: 0.8582 - loss: 0.9466 - val_accuracy: 0.8993 - val_loss: 0.7542 - learning_rate: 3.0000e-06\nEpoch 5/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8575 - loss: 0.9332\nEpoch 5: val_accuracy did not improve from 0.89929\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 331ms/step - accuracy: 0.8575 - loss: 0.9332 - val_accuracy: 0.8964 - val_loss: 0.7629 - learning_rate: 3.0000e-06\nEpoch 6/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.8620 - loss: 0.9310\nEpoch 6: val_accuracy did not improve from 0.89929\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 331ms/step - accuracy: 0.8620 - loss: 0.9310 - val_accuracy: 0.8966 - val_loss: 0.7559 - learning_rate: 3.0000e-06\nEpoch 7/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8651 - loss: 0.9261\nEpoch 7: val_accuracy did not improve from 0.89929\n\nEpoch 7: ReduceLROnPlateau reducing learning rate to 1.500000053056283e-06.\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 332ms/step - accuracy: 0.8651 - loss: 0.9261 - val_accuracy: 0.8976 - val_loss: 0.7582 - learning_rate: 3.0000e-06\nEpoch 8/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8576 - loss: 0.9358\nEpoch 8: val_accuracy did not improve from 0.89929\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 332ms/step - accuracy: 0.8576 - loss: 0.9358 - val_accuracy: 0.8981 - val_loss: 0.7526 - learning_rate: 1.5000e-06\nEpoch 9/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8648 - loss: 0.9205\nEpoch 9: val_accuracy improved from 0.89929 to 0.89978, saving model to /kaggle/working/models/best_resize.keras\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 334ms/step - accuracy: 0.8648 - loss: 0.9205 - val_accuracy: 0.8998 - val_loss: 0.7549 - learning_rate: 1.5000e-06\nEpoch 10/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8610 - loss: 0.9227\nEpoch 10: val_accuracy did not improve from 0.89978\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 331ms/step - accuracy: 0.8610 - loss: 0.9227 - val_accuracy: 0.8961 - val_loss: 0.7550 - learning_rate: 1.5000e-06\nEpoch 11/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8617 - loss: 0.9223\nEpoch 11: val_accuracy did not improve from 0.89978\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 7.500000265281415e-07.\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 332ms/step - accuracy: 0.8617 - loss: 0.9223 - val_accuracy: 0.8993 - val_loss: 0.7568 - learning_rate: 1.5000e-06\nEpoch 12/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8743 - loss: 0.9043\nEpoch 12: val_accuracy did not improve from 0.89978\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 332ms/step - accuracy: 0.8743 - loss: 0.9043 - val_accuracy: 0.8971 - val_loss: 0.7550 - learning_rate: 7.5000e-07\nEpoch 13/18\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.8664 - loss: 0.9045\nEpoch 13: val_accuracy did not improve from 0.89978\n\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 331ms/step - accuracy: 0.8664 - loss: 0.9045 - val_accuracy: 0.8983 - val_loss: 0.7556 - learning_rate: 7.5000e-07\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 8.\nLoaded best resize model: /kaggle/working/models/best_resize.keras\nSaved final resized model -> /kaggle/working/models/best_phaseB.keras\n\nFinal test accuracy (320×320): 0.8972\n              precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000        24\n           1     0.9444    1.0000    0.9714        17\n           2     0.9545    1.0000    0.9767        21\n           3     0.6875    0.6875    0.6875        16\n           4     0.7692    0.6667    0.7143        15\n           5     0.8125    0.6500    0.7222        20\n           6     1.0000    1.0000    1.0000        19\n           7     0.9048    0.9048    0.9048        21\n           8     0.8500    0.9444    0.8947        18\n           9     0.7895    1.0000    0.8824        15\n          10     1.0000    1.0000    1.0000        18\n          11     0.9048    1.0000    0.9500        19\n          12     1.0000    0.9333    0.9655        15\n          13     1.0000    0.9333    0.9655        15\n          14     1.0000    0.8125    0.8966        16\n          15     0.9333    0.8750    0.9032        16\n          16     0.9412    0.9412    0.9412        17\n          17     0.8750    0.8750    0.8750        16\n          18     1.0000    0.8889    0.9412        18\n          19     1.0000    0.8667    0.9286        15\n          20     0.7692    0.6250    0.6897        16\n          21     0.8824    0.9375    0.9091        16\n          22     1.0000    1.0000    1.0000        16\n          23     0.8000    0.9524    0.8696        21\n          24     0.2857    0.1333    0.1818        15\n          25     0.9333    0.8750    0.9032        16\n          26     1.0000    0.9375    0.9677        16\n          27     1.0000    0.9375    0.9677        16\n          28     1.0000    1.0000    1.0000        15\n          29     0.9333    0.8750    0.9032        16\n          30     0.8696    0.9524    0.9091        21\n          31     0.8667    0.8125    0.8387        16\n          32     1.0000    1.0000    1.0000        18\n          33     1.0000    1.0000    1.0000        16\n          34     1.0000    0.8235    0.9032        17\n          35     0.9375    1.0000    0.9677        15\n          36     0.8261    0.9048    0.8636        21\n          37     0.9000    0.9474    0.9231        19\n          38     0.8824    0.8333    0.8571        18\n          39     1.0000    1.0000    1.0000        18\n          40     0.8500    1.0000    0.9189        17\n          41     0.8889    0.8000    0.8421        20\n          42     1.0000    0.9524    0.9756        21\n          43     0.8667    0.6842    0.7647        19\n          44     0.8667    1.0000    0.9286        26\n          45     1.0000    1.0000    1.0000        16\n          46     0.8696    1.0000    0.9302        20\n          47     0.7895    0.8333    0.8108        18\n          48     0.9524    1.0000    0.9756        20\n          49     0.7895    0.8333    0.8108        18\n          50     0.9444    1.0000    0.9714        17\n          51     1.0000    0.9333    0.9655        15\n          52     0.8182    1.0000    0.9000        18\n          53     0.9565    1.0000    0.9778        22\n          54     0.8750    0.7778    0.8235        18\n          55     0.9412    1.0000    0.9697        16\n          56     0.9444    1.0000    0.9714        17\n          57     1.0000    1.0000    1.0000        20\n          58     0.9524    0.9524    0.9524        21\n          59     0.9333    0.9333    0.9333        15\n          60     0.9167    0.9167    0.9167        24\n          61     1.0000    1.0000    1.0000        21\n          62     0.8421    1.0000    0.9143        16\n          63     0.7037    0.9048    0.7917        21\n          64     0.5417    0.6500    0.5909        20\n          65     0.7647    0.8125    0.7879        16\n          66     0.9333    0.9333    0.9333        15\n          67     1.0000    0.7500    0.8571        16\n          68     0.9048    0.9048    0.9048        21\n          69     0.6111    0.7333    0.6667        15\n          70     0.9412    1.0000    0.9697        16\n          71     0.8667    0.8667    0.8667        15\n          72     0.9444    1.0000    0.9714        17\n          73     0.6471    0.6875    0.6667        16\n          74     0.8333    1.0000    0.9091        15\n          75     0.9524    0.9524    0.9524        21\n          76     1.0000    0.9444    0.9714        18\n          77     0.7917    0.9500    0.8636        20\n          78     0.9412    1.0000    0.9697        16\n          79     0.9444    0.8947    0.9189        19\n          80     0.9412    0.9412    0.9412        17\n          81     0.9375    1.0000    0.9677        15\n          82     0.9333    0.9333    0.9333        15\n          83     1.0000    0.9375    0.9677        16\n          84     0.8824    0.9375    0.9091        16\n          85     0.8261    0.9500    0.8837        20\n          86     1.0000    0.9500    0.9744        20\n          87     1.0000    1.0000    1.0000        15\n          88     1.0000    0.9375    0.9677        16\n          89     1.0000    0.6000    0.7500        15\n          90     0.8235    0.9333    0.8750        15\n          91     1.0000    0.9333    0.9655        15\n          92     0.8235    0.8750    0.8485        16\n          93     0.9375    0.9375    0.9375        16\n          94     0.9375    0.9375    0.9375        16\n          95     1.0000    0.9333    0.9655        15\n          96     1.0000    1.0000    1.0000        15\n          97     1.0000    1.0000    1.0000        15\n          98     1.0000    0.8000    0.8889        15\n          99     1.0000    1.0000    1.0000        15\n         100     0.9333    0.9333    0.9333        15\n         101     0.8421    0.9412    0.8889        17\n         102     0.9333    0.9333    0.9333        15\n         103     0.8500    0.9444    0.8947        18\n         104     0.8182    0.5625    0.6667        16\n         105     0.7647    0.8667    0.8125        15\n         106     0.8333    0.6667    0.7407        15\n         107     0.9500    0.9500    0.9500        20\n         108     0.9048    0.9500    0.9268        20\n         109     0.8462    0.7857    0.8148        14\n         110     0.9333    0.9333    0.9333        15\n         111     0.7222    0.7222    0.7222        18\n         112     0.9333    0.8750    0.9032        16\n         113     0.8235    0.8750    0.8485        16\n         114     0.7692    0.6250    0.6897        16\n         115     0.6667    0.6667    0.6667        15\n         116     1.0000    0.8333    0.9091        18\n         117     0.8824    1.0000    0.9375        15\n         118     1.0000    0.6842    0.8125        19\n         119     0.8750    0.8750    0.8750        16\n\n    accuracy                         0.8972      2072\n   macro avg     0.8991    0.8941    0.8933      2072\nweighted avg     0.8994    0.8972    0.8951      2072\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Corrected: TTA + simple ensemble of best_phaseB + final_model_320\nimport tensorflow as tf\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# config\nIMG = (320, 320)\nBATCH = 24\nSRC_TEST = str(Path(PROCESSED_ROOT) / \"test\")\nm1_path = MODEL_DIR / \"best_phaseB.keras\"\nm2_path = MODEL_DIR / \"final_model_320.keras\"   # may exist after resize\nmodels_to_use = []\nif m1_path.exists():\n    models_to_use.append(tf.keras.models.load_model(str(m1_path)))\nif m2_path.exists():\n    models_to_use.append(tf.keras.models.load_model(str(m2_path)))\nif not models_to_use:\n    raise FileNotFoundError(\"No candidate models found (best_phaseB/final_model_320).\")\n\nprint(\"Using models:\", [getattr(m, \"name\", \"model\") for m in models_to_use])\n\n# build test dataset (320)\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    SRC_TEST, labels='inferred', label_mode='categorical',\n    image_size=IMG, batch_size=BATCH, shuffle=False, seed=777\n).prefetch(tf.data.AUTOTUNE)\n\ndef tta_variants(batch_images):\n    orig = tf.cast(batch_images, tf.float32)\n    flip = tf.image.flip_left_right(orig)\n    crop = tf.image.central_crop(orig, 0.92)\n    crop = tf.image.resize(crop, IMG)\n    cont = tf.image.adjust_contrast(orig, 1.08)\n    variants = tf.concat([orig, flip, crop, cont], axis=0)  # (4*B, H, W, 3)\n    return variants, 4\n\ny_true_all = []\ny_pred_all = []\nfor imgs, labs in test_ds:\n    batch_size = imgs.shape[0]\n    variants, nvar = tta_variants(imgs)  # shape (nvar*batch, H, W, 3)\n\n    model_preds = []\n    for m in models_to_use:\n        preds = m.predict(variants, verbose=0)           # (nvar*batch, C)\n        preds = preds.reshape(nvar, batch_size, -1)      # (nvar, batch, C)\n        preds = preds.mean(axis=0)                       # (batch, C)\n        model_preds.append(preds)\n\n    ensemble_preds = np.mean(np.stack(model_preds, axis=0), axis=0)  # (batch, C)\n    y_true_all.extend(np.argmax(labs.numpy(), axis=1).tolist())\n    y_pred_all.extend(np.argmax(ensemble_preds, axis=1).tolist())\n\nacc = accuracy_score(y_true_all, y_pred_all)\nprint(f\"\\nEnsembled TTA Test accuracy: {acc:.4f}\")\nprint(\"\\nClassification report:\")\nprint(classification_report(y_true_all, y_pred_all, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T19:09:06.959930Z","iopub.execute_input":"2025-09-24T19:09:06.960720Z","iopub.status.idle":"2025-09-24T19:09:59.403207Z","shell.execute_reply.started":"2025-09-24T19:09:06.960695Z","shell.execute_reply":"2025-09-24T19:09:59.402461Z"}},"outputs":[{"name":"stdout","text":"Using models: ['functional_32']\nFound 2072 files belonging to 120 classes.\n\nEnsembled TTA Test accuracy: 0.9030\n\nClassification report:\n              precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000        24\n           1     0.9444    1.0000    0.9714        17\n           2     0.9545    1.0000    0.9767        21\n           3     0.7333    0.6875    0.7097        16\n           4     0.7692    0.6667    0.7143        15\n           5     0.8125    0.6500    0.7222        20\n           6     1.0000    1.0000    1.0000        19\n           7     0.9048    0.9048    0.9048        21\n           8     0.8500    0.9444    0.8947        18\n           9     0.7895    1.0000    0.8824        15\n          10     1.0000    1.0000    1.0000        18\n          11     0.9048    1.0000    0.9500        19\n          12     0.9333    0.9333    0.9333        15\n          13     1.0000    1.0000    1.0000        15\n          14     1.0000    0.8750    0.9333        16\n          15     0.9333    0.8750    0.9032        16\n          16     0.9375    0.8824    0.9091        17\n          17     0.8750    0.8750    0.8750        16\n          18     1.0000    0.8889    0.9412        18\n          19     1.0000    0.8667    0.9286        15\n          20     0.7692    0.6250    0.6897        16\n          21     1.0000    0.8750    0.9333        16\n          22     1.0000    1.0000    1.0000        16\n          23     0.7692    0.9524    0.8511        21\n          24     0.3333    0.1333    0.1905        15\n          25     0.9375    0.9375    0.9375        16\n          26     1.0000    0.9375    0.9677        16\n          27     1.0000    0.8750    0.9333        16\n          28     1.0000    1.0000    1.0000        15\n          29     0.9412    1.0000    0.9697        16\n          30     0.8696    0.9524    0.9091        21\n          31     0.9231    0.7500    0.8276        16\n          32     1.0000    1.0000    1.0000        18\n          33     1.0000    1.0000    1.0000        16\n          34     1.0000    0.8235    0.9032        17\n          35     0.9375    1.0000    0.9677        15\n          36     0.8261    0.9048    0.8636        21\n          37     0.9000    0.9474    0.9231        19\n          38     0.9375    0.8333    0.8824        18\n          39     1.0000    1.0000    1.0000        18\n          40     0.9444    1.0000    0.9714        17\n          41     0.8889    0.8000    0.8421        20\n          42     1.0000    0.9524    0.9756        21\n          43     0.8571    0.6316    0.7273        19\n          44     0.8667    1.0000    0.9286        26\n          45     1.0000    1.0000    1.0000        16\n          46     0.9091    1.0000    0.9524        20\n          47     0.8333    0.8333    0.8333        18\n          48     0.9524    1.0000    0.9756        20\n          49     0.7895    0.8333    0.8108        18\n          50     0.9444    1.0000    0.9714        17\n          51     1.0000    0.9333    0.9655        15\n          52     0.8182    1.0000    0.9000        18\n          53     0.9565    1.0000    0.9778        22\n          54     0.8824    0.8333    0.8571        18\n          55     0.9375    0.9375    0.9375        16\n          56     0.9444    1.0000    0.9714        17\n          57     0.9524    1.0000    0.9756        20\n          58     0.9524    0.9524    0.9524        21\n          59     0.9333    0.9333    0.9333        15\n          60     0.9167    0.9167    0.9167        24\n          61     1.0000    1.0000    1.0000        21\n          62     0.8421    1.0000    0.9143        16\n          63     0.7037    0.9048    0.7917        21\n          64     0.5600    0.7000    0.6222        20\n          65     0.7778    0.8750    0.8235        16\n          66     0.9333    0.9333    0.9333        15\n          67     1.0000    0.8125    0.8966        16\n          68     0.9048    0.9048    0.9048        21\n          69     0.6316    0.8000    0.7059        15\n          70     1.0000    1.0000    1.0000        16\n          71     0.8125    0.8667    0.8387        15\n          72     0.9444    1.0000    0.9714        17\n          73     0.7059    0.7500    0.7273        16\n          74     0.8824    1.0000    0.9375        15\n          75     0.9524    0.9524    0.9524        21\n          76     1.0000    0.9444    0.9714        18\n          77     0.8261    0.9500    0.8837        20\n          78     0.8889    1.0000    0.9412        16\n          79     0.9474    0.9474    0.9474        19\n          80     0.8000    0.9412    0.8649        17\n          81     0.9375    1.0000    0.9677        15\n          82     0.9333    0.9333    0.9333        15\n          83     1.0000    1.0000    1.0000        16\n          84     0.8824    0.9375    0.9091        16\n          85     0.7917    0.9500    0.8636        20\n          86     1.0000    0.9500    0.9744        20\n          87     0.9375    1.0000    0.9677        15\n          88     1.0000    0.9375    0.9677        16\n          89     1.0000    0.6000    0.7500        15\n          90     0.8235    0.9333    0.8750        15\n          91     1.0000    1.0000    1.0000        15\n          92     0.8235    0.8750    0.8485        16\n          93     0.9375    0.9375    0.9375        16\n          94     0.9375    0.9375    0.9375        16\n          95     1.0000    0.9333    0.9655        15\n          96     1.0000    1.0000    1.0000        15\n          97     1.0000    1.0000    1.0000        15\n          98     1.0000    0.8000    0.8889        15\n          99     1.0000    1.0000    1.0000        15\n         100     0.9333    0.9333    0.9333        15\n         101     0.8421    0.9412    0.8889        17\n         102     0.9333    0.9333    0.9333        15\n         103     0.8500    0.9444    0.8947        18\n         104     0.8462    0.6875    0.7586        16\n         105     0.7778    0.9333    0.8485        15\n         106     0.7692    0.6667    0.7143        15\n         107     0.9524    1.0000    0.9756        20\n         108     1.0000    1.0000    1.0000        20\n         109     0.9167    0.7857    0.8462        14\n         110     0.9333    0.9333    0.9333        15\n         111     0.7778    0.7778    0.7778        18\n         112     0.9333    0.8750    0.9032        16\n         113     0.8750    0.8750    0.8750        16\n         114     0.9091    0.6250    0.7407        16\n         115     0.7143    0.6667    0.6897        15\n         116     1.0000    0.8333    0.9091        18\n         117     0.9375    1.0000    0.9677        15\n         118     1.0000    0.6316    0.7742        19\n         119     0.8667    0.8125    0.8387        16\n\n    accuracy                         0.9030      2072\n   macro avg     0.9054    0.9001    0.8991      2072\nweighted avg     0.9055    0.9030    0.9006      2072\n\n","output_type":"stream"}],"execution_count":25}]}